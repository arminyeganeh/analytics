# Random Sampling

"Random sampling is the process that most likely leads to representative samples. With the simplest ideal random sampling, all observations in the population have the same chance of being selected into the sample. In practice, that chance can vary. Which observations are selected is determined by a random rule. For the purpose of getting representative samples, selection rules are random if they are not related to the distribution of the variables in the data. Textbook examples of random rules include throwing dice or drawing balls from urns. In practice, most random samples are selected with the help of random numbers generated by computers. These numbers are parts of a sequence of numbers that is built into the computer. The sequence produces numbers without a recognizable pattern. Where the sequence starts is either specified by someone or determined by the date and time the process is launched. In a sense these numbers are not truly random as they always come up the same if started from the same point, in contrast with repeatedly throwing dice or drawing balls from urns. Nevertheless, that is not a real concern here because this selection rule is unrelated to the distribution of variables in any real-life data. Other methods of random sampling include fixed rules that are unrelated to the distribution of variables in the data. Good examples are selecting people with odd-numbered birth dates (a 50% sample), or people with birthdays on the 1 5th of every month (approx. 3% sample). Again, these rules may not be viewed as "truly random" in a stricter sense, but that's not a concern for representation as long as the rules are not related to the variables used in the analysis. In contrast, non-random sampling methods may lead to selection bias. Non-random sampling methods are related to important variables. In other words, they have a higher or lower likelihood â€ƒ of selecting observations that are different in some important variables. As a result, the selected observations tend to be systematically different from the population they are drawn from. Consider two examples of non-random sampling methods. Selecting people from the first half of an alphabetic order is likely to lead to selection bias because people with different names may belong to different groups of society. Selecting the most recently established 10% of firms is surely not random for many reasons. One reason is called survivor bias: newly established firms include those that would fail within a short time after their establishment while such firms are not present among older firms. The practice questions will invite you to evaluate particular sampling methods and come up with other good and not-so-good methods. Random sampling works very well if the sample is large enough. In small samples, it is possible that by chance, we pick observations that are not representative of the population. Consider for instance whether samples represent the age distribution of the population of a city. By picking a sample of two people, the share of young and older people may very well be different from their shares in the entire population. Thus, there is a considerable chance that this sample ends up being not representative even though it's a random sample. However, in a random sample of a thousand people, the share of young and old people is likely to be very similar to their shares in the population, leading to a representative sample. The larger the sample, the larger the chance of picking a representative sample. An important, although not necessarily intuitive, fact is that it is the size of the sample that matters and not its size as a proportion of the entire population. A sample of five thousand observations may equally well represent populations of fifty thousand, ten million, or three hundred million. Quite naturally, the larger the random sample, the better But real life raises other considerations such as costs and time of data collection. How large a random sample is large enough depends on many things. We shall return to this question when we first discuss inference from samples to populations, in Chapter 5. Random sampling is the best method of producing representative samples. True, it is not bulletproof, with a tiny chance a sample may be way off. But that tiny chance is really tiny, especially for large samples. Nevertheless, the fact that it is not literally bullet-proof makes some people uncomfortable when they first encounter it. In fact, it took a lot of evidence to convince most data users of the merits of random sampling. In practice, sampling often starts with a sampling frame: the list of all observations from which the sample is to be drawn. Incomplete and biased coverage may arise at this stage: the sampling frame may not include the entire population or may include observations that are not part of the population to be represented. Ideally, data is collected from all members of a sample. Often, however, that is not possible. Surveys need respondents who are willing to participate and answer the questions. The fraction of people that were successfully contacted and who answered the questionnaire is called the response rate. A low response rate increases the chance of selection bias. That is, of course, not necessarily true: a sample with an 80% response rate may be more biased than another sample with a 40% response rate. It is good practice to report response rates with the data description and, if possible, to benchmark variables available in the population." (Bekes, 2021)&#x20;

&#x20;

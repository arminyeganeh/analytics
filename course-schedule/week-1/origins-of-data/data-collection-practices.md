# Data Collection Practices

"Several good practices in data collection are recognized to increase or help assess data quality. Some are general across many methods; others are specific. Carrying out one or more pilot studies before data collection is general advice. To pilot a data collection method means to try it out in microcosm before doing the whole thing. Piloting is more powerful the more features of the final data collection are included. In web scraping this may mean small-scale collection of data from all websites across all kinds of items that will be relevant. In web surveys it may include recruiting a few respondents as well as asking them to fill out the entire questionnaire. With complex data collection, piloting may come in several steps, such as identifying the sampling frame, drawing a sample, identifying observations or recruiting respondents, and collecting the data itself by scraping, interviewing. Sometimes these steps are given different names as they get to include more and more parts of the entire data collection process (pilot, pretest, field rehearsal, and so on). When people are involved in data collection, it is good practice to give them precise instructions to follow. An important objective of these is to get the actual content of measured variables as close as possible to their intended contents, thus increasing their validity. These practices also help with comparability and reliability by inducing different people to measure similar things in similar ways. For example, in interview-based surveys, precise instructions usually include questions to be read out (as opposed to letting interviewers ask questions using their own words), when and exactly how to clarify things, and how to translate answers into what is to be recorded. Instructions need to be easy to follow, so a balance needs to be found in how detailed and how accessible instructions are. Another good practice is training people that participate in data collection in how to follow those instructions and how to make other kinds of decisions. Good training involves many hands-on exercises with examples that are likely to come up during data collection. Training of interviewers for complex surveys may take several days and is often very costly Nevertheless, it is important to give thorough training to people involved in the data collection in order to ensure high data quality. Less frequent but very useful practices aim at assessing data quality as part of the data collection. For example, the validity of measures in surveys may be assessed with the help of cognitive interviews. These ask respondents to explain why they answered a survey question the way they did. Another technique is asking a survey question in slightly different ways for different respondents (or the same respondents) to see if differences in wording that should not matter make a difference in the answers. A useful practice to evaluate reliability is testâ€”retest measurement: measuring the same thing more than once within the same data collection process. For example, the price of the same product in the same store may be recorded by two people, independent of each other. Or the same question may be asked of the same respondent twice within the same questionnaire, preferably with many questions in-between. Such a test-retest measurement took place within the World Management Survey: it re-interviewed several hundred firms to assess the reliability of the management quality scores. There are good practices that help assess coverage issues, too. Whether nonresponse in a survey leads to severe biases may be assessed by giving some of the would-be respondents higher incentives to participate. If that results in a higher response rate, we may compare the distributions of variables across respondents with and without the extra incentives to see if different response rates lead to different distributions. There are many other techniques and practices that data collection may include to assess various dimensions of data quality. Making use of all is practically impossible. Nevertheless, it can be very useful to include one or two of them if data collectors are concerned with one or two issues in particular The results of these techniques can not only shed light on the extent of particular issues but they may be used to mitigate their consequences in the course of the analysis. Very often, data collection is a complex task. Teamwork here is especially useful as designing and implementing data collection may require a wide range of expertise. The more complex the process, the larger the benefits of advice and collaboration. However, even seemingly simple data collection tasks may have issues that inexperienced researchers are not aware of and can result in inferior data quality. Thus, we think it always makes sense to seek advice and, if needed, mentoring during all stages of data collection. Garbage in, garbage out: if the data we collect ends up having crucial flaws, our analysis will not be able to answer our question. It's better to minimize that possibility if we can." (Bekes, 2021)&#x20;

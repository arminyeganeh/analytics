---
description: Week 2, Lecture A2.1, 1500 words, 1 hour to complete
---

# Exploring Data





3.A2 Case Study

Distance to city center (miles) Figure 3.4 Histogram of distance to the city center. Source: hotels-vienna dataset. Vienna, all hotels with 3 to 4 stars. N=217. For this histogram we used 0.5-mile-wide bins. This way we can see the extreme values in more detail even though the rest of the histogram looks a bit less nice (too uneven). The y axis shows the frequency. The histogram shows three hotels above 8 miles: two at around 1 1 miles and one at close to 1 3 miles. We see another group of hotels between 6 and 8 miles that are a little separated from the rest of the distribution (no value between 8 and 1 1 miles). We decided to drop the three hotels that are more than 8 miles away from the city center and keep the ones at 6 to 8 miles. The extreme values we dropped are not errors. But they are values that would not be relevant for the main question of the analysis: finding hotels that are underpriced relative to their distance to the city center (and their quality). Eleven and 13 miles are far enough from the city center that we think we wouldn't choose these hotels if our aim was to stay in Vienna to explore the city. At the same time we didn't discard the hotels at 6 to 8 miles, thinking that maybe some of them are so inexpensive that they could be good deals even factoring in their distance. Note that this decision is arbitrary, but one such decision is necessary. In a thorough analysis, we would see if including the 8+ miles hotels, or excluding the 6—8 miles hotels, changes the answer to our question. To better understand the features of hotels far from the center, we investigated our "city\_actual" variable. It turns out that even within the 8-mile radius, a few hotels are in villages (such as Voesendorf) that are related to Vienna but are not Vienna proper. Hence, we decided to drop these hotels, too. The result is a sample of 208 hotels. Next we looked at prices, using the data of the 208 hotels that are within 8 miles from the city center and are in Vienna Earlier, we pointed out a single observation with a price of 1012 dollars. This is an extreme value indeed. We dropped it because we decided that it is almost surely an error. It's a room in a 3 star hotel and is unlikely to cost over a thousand dollars. Moreover, in the hotels-europe dataset that contains prices for several dates for these same hotels, and many more, the price of this hotel is around 100 dollars on all other dates not 1000 dollars. We have identified, in Figure 3.2b, an additional observation with an extreme value, close to 400 dollars. We decided to keep this observation. This is a high price for this kind of a hotel (3 stars). At the same time, inspecting the hotels-europe dataset reveals another date with a similarly high

price, and the prices on the rest of the dates, while considerably lower, are not lower by an order of magnitude that would indicate a digit error. Thus, we can't conclude that this extreme value is an error. To summarize, our exploratory analysis led us to focus our sample. Our key steps were:

1. We started with full data, N = 428.
2. We inspected the histograms of the qualitative variables. • Accommodation type — could be apartment, house and so on; kept hotels only, N = 264. • Stars — kept only: 3, 3.5, 4 stars, N = 218.
3. We looked at quantitative variables, focusing on extreme values. • Price: the extreme value of 1012 dollars is a likely error, dropped it; kept all others, N= 217. • Distance: some hotels are far away; defined cutoff; dropped beyond 8 miles, 214. • Distance, one more step: looked at variable city\_actual, realized that some hotels are not in Vienna proper; dropped them, N = 207.
4. The final sample is hotels with 3 to 4 stars, below 400 dollars, less than 8 miles from center, in Vienna proper, N = 207. Good Graphs: Guidelines for Data Visualization Now that we have introduced visualization of distributions, let's pause and spend some time on how to produce good graphs in general. These thoughts are meant to guide all decisions that go into producing graphs. They correspond to the practice of data visualization professionals; see some important references at the end of the chapter. Before we begin, let us point out that our principles and suggestions are aimed at data analysts not visual designers. Typically, data analysts want to spend less time designing graphs than visual designers. As a result, they are more likely to use ready-made graph types and templates, and they benefit more from following a few simple rules instead of engaging in a creative process each and every time. Just like with any of our advice, this is not a must do list. Instead it shows how to think about decisions data analysts must take. You may take other decisions, of course. But those decisions should be conscious instead of letting default settings determine the look of your graphs. The starting principle is that all of our decisions should be guided by the usage of the graph. The usage of a graph is a summary concept to capture what we want to show and to whom. Its main elements are purpose, focus, and audience. Table 3.1 explains these concepts and gives some examples. Note that some of the examples use graphs that we haven't introduced yet; this is because we want the advice to serve as reference later on. Once usage is clear, the first set of decisions to make are about how we convey information: how to show what we want to show. For those decisions it is helpful to understand the entire graph as the overlay of three graphical objects: 1 . Geometric object: the geometric visualization of the information we want to convey, such as a set of bars, a set of points, a line; multiple geometric objects may be combined.
5. Scaffolding: elements that support understanding the geometric object, such as axes, labels, and legends.
6. Annotation: adding anything else to emphasize specific values or explain more detail. 3.5 Good Graphs: Guidelines for Data Visualization Table 3.1 Usage of a graph Concept Explanation Typical cases Examples Purpose Focus Audience The message that the graph should convey One graph, one message To whom the graph wants to convey its message Main conclusion of the analysis An important feature of the data Documenting many features of a variable Multiple related graphs for multiple messages Wide audience Non-data-analysts with domain knowledge Analysts y and x are positively associated There are extreme values of y at the right tail of the distribution All potentially important properties of the distribution of y A histogram of ythat identifies extreme values, plus a box plot of y that summarizes many other features of its distribution Journalists Decision makers Fellow data analysts, or our future selves when we want to reproduce the analysis When we design a graph, there are many decisions to make. In particular, we need to decide how the information is conveyed: we need to choose a geometric object, which is the main object of our graph that visualizes the information we want to show. The geometric object is often abbreviated as a geom. The same information may be conveyed with the help of different geometric objects, such as bar charts for a histogram or a curved line for a density plot. In practice, a graph may contain more than one geometric object, such as a set of points together with a line, or multiple lines. Choosing the details of the geometric object, or objects, is called encoding. Encoding is about how we convey the information we want using the data we have, and it means choosing elements such as height, position, color shade. For a graph with a set of bars as the geometric object, the information may be encoded in the height of these bars. But we need to make additional choices, too. These include general ones such as color and shade as well as choices specific to the geometric object, such as width of the bars or lines, or size of the dots. In principle, a graph can be built up freely from all kinds of graphical objects. Data visualization experts and designers tend to follow this bottom-up approach. In contrast, most data analysts start with choosing a predefined type of graph: a single geometric object or a set of some geometric objects and a scaffolding, possibly some annotation. One graph type is the histogram that we introduced earlier in this chapter. Histograms are made of a set of bars as a geometric object, with the information in the data (frequency) encoded in the height of the ban The scaffolding includes an x axis with information on the bins, and a y axis denoting either the absolute (count) or relative frequency (percent). We'll introduce many more graph types in this chapter and subsequent chapters of the textbook. Table 3.2 offers some details and advice. The next step is scaffolding: deciding on the supporting features of the graph such as axes, labels, and titles. This decision includes content as well as format, such as font type and size. Table 3.3 summarizes and explains the most important elements of scaffolding. Table 3.2 The geometric object, its encoding, and graph types Concept General advice Examples Geometric object One or more geoms Encoding Graph type Pick an object suitable for the information to be conveyed May combine more than one geom to support message or add context Pick one encoding only Can pick a standard object to convey information Set of bars comparing quantity A line showing value over time Dots for the values of a time series variable over time, together with a trend line Histogram: height of bars encodes information (frequency) Don't apply different colors or shades Histogram: bars to show frequency Scatterplot: values of two variables shown as a set of dots Table 3.3 Scaffolding Element General advice Examples Graph title Title should be part of the text; it Swimming pool ticket sales and temperature should be short emphasizing main message Swimming pool sales fluctuate with weather Axis title Each axis should have a title, with the Distance to city center (miles) name of the actual variable and unit of measurement Household income (thousand US dollars) Axis labels Value numbers on each axis, next to 0, 2, 4, 6, 8, 10, 12 14 miles for distance to city tics, should be easy to read center Gridlines Add horizontal and, if applicable, Vertical gridlines for histogram vertical gridlines to help reading off Both horizontal and vertical gridlines for numbers scatterplots Legends Add legend to explain different Two groups, such as "male" and "female" elements of the geometric object Time series graphs for two variables; it's best to Legends are best if next to the element they explain put legends next to each line Fonts Large enough size so the audience can read them Font size "10"

Lastly, we may add annotation — if there is something else we want to add or emphasize. Such additional information can help put the graph into context, emphasize some part of it. The two main elements of annotation are notes and visual emphasis, see Table 3.4 for some advice.

3.A3 Case Study Table 3.4 Annotation Concept General advice Examples Graph notes Added emphasis Add notes to describe all important details about how the graph was produced and using what data May add extra annotation to graph to emphasize main message Lowess non-parametric regression with scatterplot Hotels-vienna dataset. Vienna, all hotels with 3 to 4 stars. N=217 A vertical line or circle showing extreme values on a histogram An arrow pointing to a specific observation on a scatterplot CASE STUDY — Finding a Good Deal among Hotels: Data Exploration The anatomy of a graph Let us use a previous graph here, to illustrate the most important parts of a good graph. Recall that we should should keep in mind usage, encoding, scaffolding, annotation. We use a previous graph with the histogram of hotel distance to the city center (Figure 3.4), but here we added some annotation (Figure 3.5). Usage. We use this graph to search for extreme values and document them. The main message is that the three hotels that are located more than 8 miles away from the city center are separate from the rest. The target audience is a specialized one: fellow data analysts. The figure may serve to document the reasons of our decisions, again a special usage. Encoding. The graph shows the distribution in enough detail to spot extreme values, but it also shows the main part of the distribution to put those extreme values in context. Our encoding choice was a histogram with a 0.5-mile bin. Alternative choices would have been a density plot or wider or narrower bins for the histogram. Choosing the histogram with a 0.5-mile bin led to a balance for the usage of the graph: showing the main part distribution and the extreme values. One message, one encoding: we use a single color as bar height is enough to help compare through distance bins. Scaffolding. The x axis denotes distance to city center Although bins are every 0.5 mile, the labels are at 2-mile intervals to help readability. The y axis denotes the number of hotels per bin. It is absolute frequency here not percentage, because our focus is on counting observations with extreme values. Notice the labels on the yaxis: they are in increments of 10. The scaffolding includes horizontal and vertical gridlines to help reading off numbers. Annotation. We point out the main message of the graph: the three hotels beyond 8 miles from the center appear to form their own cluster. We used a colored rectangle, but we could have circled them, or had an arrow pointed at them. For a scientific audience we could have skipped that annotation because that audience would understand the issue anyway and may appreciate a clean histogram.

Figure 3.5 Histogram of distance to the city center Source: hotels-vienna dataset. Vienna, all hotels with 3 to 4 stars. N=217. A histogram of a quantitative variable can inform us about the shape of the distribution, whether it has extreme values, or where its center is approximately. But visual displays don't produce the numbers that are often important to answer our questions. How far are hotels from the city center in general? What's the spread of prices? How skewed is the distribution of customer ratings? To answer such questions we need numerical summaries of variables. They are called statistics, and this section covers the most important ones. A statistic of a variable is a meaningful number that we can compute from the data. Examples include mean income or the range of prices. Basic summary statistics are numbers that describe the most important features of the distribution of a variable. Summary statistics can answer questions about variables in our data, and they often lead to further questions to examine. Most readers are probably well acquainted with many summary statistics, including the mean, the median (the middle value), various quantiles (terciles, quartiles, percentiles), and the mode (the value with the highest frequency in the data). The mean, median, and mode are also called measures of central tendency, because they give an answer to where the center of the distribution is. Those answers may be the same (the mean, median, and mode may be equal, or very close to each other), or they may be different. Importantly, we use the terms mean, average, and expected value as synonyms, and we use the notation E\[x] as well ask. 3.6 Summary Statistics for Quantitative Variables

The mean of a quantitative variable is the value that we can expect for a randomly chosen observation. The mean of a 0/1 binary variable is the proportion of observations with value 1. No observation would have the expected value as it is between 0 and 1 since the value of the binary variable can be only 0 or 1. Similarly, most readers know the most important measures of spread, such as the range (the difference between the largest and smallest value), inter-quantile ranges (e.g., the 90—10 percentile range, or the inter-quartile range), the standard deviation, and the variance. The standard deviation captures the typical difference between a randomly chosen observation and the mean. The variance is the square of the standard deviation. The variance is a less intuitive measure, but it is easier to work with because it is a mean value itself. The formulae are: Var\[x] (3.1) n Std\[x] (3.2) Note that alternative formulae for the variance and the standard deviation divide by n — 1 not n. Most data are large enough that this makes no practical difference. It turns out that dividing by n — 1 is the correct formula if we use the statistic in the data to infer the standard deviation in the population that our data represents (see more details in Chapter 5, Section 5.12). Since it makes little difference in practice, and dividing by n is easier to remember, we will continue to divide by n in this textbook. The standard deviation is often used to re-calculate differences between values of a quantitative variable, in order to express those values relative to what a typical difference would be. In a formula, this amounts to dividing the difference by the standard deviation. Such measures are called standardized differences. A widely used standardized difference is from the mean value; it is called the standardized value of a variable or the z-score of the variable. Xstandardized — (3.3) Std\[x] While measures of central value (such as mean, median) and spread (such as range, standard deviation) are usually well known, summary statistics that measure skewness are less frequently used. At the same time skewness can be an important feature of a distribution, showing whether a few observations are responsible for much of the spread. Moreover, there is a very intuitive measure for skewness (which exists in a few variants). Recall that a distribution is skewed if it isn't symmetric. A distribution may be skewed in two ways, having a long left tail or having a long right tail. A long left tail means having a few observations with small values with most observations having larger values. A long right tail means having a few observations with large values with most observations having smaller values. Earlier we showed that the hotel price distributions has a long right tail — such as in Figure 3.4. That is quite typical: skewness with a long right tail is frequent among variables in business, economics, and policy, such as with prices, incomes, and population. The statistic of skewness compares the mean and the median and is called the mean—median measure of skewness. When the distribution is symmetric, its mean and median are the same. When it is skewed with a long right tail, the mean is larger than the median: the few very large values in the right tail tilt the mean further to the right. Conversely, when a distribution is skewed with a long left tail, the mean is smaller than the median: the few very small values in the left tail tilt the mean further to

the left. The mean-median measure of skewness captures this intuition. In order to make this measure comparable across various distributions, we use a standardized measure, dividing the difference by the standard deviation. (Sometimes this measure is multiplied by 3, and then it's called Pearson's second measure of skewness. Yet other times the difference is divided by the mean, median, or some other statistic.) Skewness = c— median\[x] (3.4) Std\[x] Table 3.5 summarizes the most important descriptive statistics we discussed.

```
Type of statistic Name of statistic	Formula	Intuitive content
```

The value we expect chosen observation Median The value of the observation in the middle Mode The value (bin) with the highest frequency Spread Range max\[x] — min\[x] Width of the interval of possible values Inter-quantile range qupper \[X] — mower X Distance between the upper quantile and the lower quantile Variance Var\[x] Standard deviation Std\[x]Typical distance between observations and the mean Skewness Mean—median E— Skewness = median (x) Std\[xl The extent to which values in the tail skewness pull the mean

CASE STUDY — Comparing Hotel Prices in Europe: Vienna vs. London Comparing distributions over two groups We are interested in comparing the hotel markets over Europe, and would like to learn about characteristics of hotel prices. To do that, let us focus on comparing the distribution of prices in Vienna to another city, London. The data we use is an extended version of the dataset we used so far. The hotels-europe dataset includes the same information we saw, for 46 cities and 10 different dates. We will explore it more in Chapter 9. For this case study, we consider the same date as earlier (weekday in November 2017) for Vienna and London.

3.B1 Case Study

We focus on hotels with 3 to 4 stars that are in the actual city of Vienna or London. We have no extreme value of price in London, so we need to drop the single, above 1000 dollars priced hotel in Vienna. In our sample, there are N 435 hotels in the London dataset compared to the N = 207 hotels in Vienna. Figure 3.6 shows two histograms side by side. To make them comparable, they have the same bin size (20 dollars), the same range of axes, and each histogram shows relative frequencies. The same range of axes means that the x axis goes up to 500 dollars both Vienna and London because the maximum price is close to 500 dollars in London. The histograms reveal many important features. Here is a selected set of observations we can make: The range is around 50 dollars in both cities but it ends below 400 dollars in Vienna while it goes close to 500 dollars in London. The London distribution of prices covers more of the higher values, and it is more spread out (i.e. has a larger difference between the minimum and maximum price). Hotel prices tend to be higher in London. Both distributions have a single mode, but their location differs. The bin with the highest frequency (the mode) in Vienna is the 80-100-dollar bin, and it is the 120—140-dollar bin in London. 300 Price (US dollars) Price (US dollars) (a) Vienna (b) London Figure 3.6 The distribution of hotel price in Vienna and London Source: hotels-europe dataset. Vienna and London, 3-4 stars hotels only, for a November 2017 weekday. Vienna: N=207, London: N=435. The same price distributions can be visualized with the help of density plots. Figure 3.7 shows the Vienna and London distributions laid on top of each other The density plots do not convey more information than the histograms. In fact, they are less specific in showing the exact range or the prevalence of extreme values. But comparing density plots on a single graph is just easier -- we can see immediately where the mass of hotels are in Vienna and in London.

Price (US dollars) Figure 3.7 Density plots of hotel prices: Vienna and London Note: Kernel density estimates with Epanechnikov smoothing method. Source: hotels-europe dataset, Vienna and London, 3—4 stars hotels only, for a November 2017 weekday. Vienna: N=207, London: N=435. We can quantify some aspects of the distributions, too. Table 3.6 contains some important summary statistics in the two datasets. Table 3.6 Descriptive statistics for hotel prices in two cities City N Mean Median Min Max Std Skew

```
London 435 202.36	186	49	491	88.13	0.186
Vienna	207 109.98	100	50	383	42.22	0.236
```

Source: hotels-europe dataset. Vienna and London, November 2017, weekday. Average price is 1 10 dollars in Vienna and 202 dollars in London. The difference is 92 dollars, which is almost an extra 90 % relative to the Vienna average. The mean is higher than the median in both cities, indicating a somewhat skewed distribution with a long right tail. Indeed, we can calculate the standardized mean—median measures of skewness, and it is more positive in Vienna ((1 10 100)/42 0.236) than in London ((202 - 1 86) / 88 O. 186). The range of prices is substantially wider in London (491 — 49 442) than in Vienna (383 — 50 — 343), and the standard deviation shows a substantially larger spread in London (88 versus 42). The first column shows that the London dataset has about twice as many observations (435 versus 207). These summary statistics are in line with the conclusions we drew by inspecting the visualized distributions. Hotel prices in London tend to be substantially higher on average. They are also more spread, with a minimum close to the Vienna minimum, but many hotels above 200 dollars. These together imply that there are many hotels in London with a price comparable to hotel prices in Vienna, but there are also many hotels with substantially higher prices. 3.7 Visualizing Summary Statistics Visualizing Summary Statistics The summary statistics we discussed are often presented in table format. But there are creative ways to combine some of them in graphs. We consider two such graphs. The more traditional visualization is the box plot, also called the box and whiskers plot shown in Figure 3.8a. The box plot is really a one-dimensional vertical graph, only it is shown with some width so it looks better. The center of a box plot is a horizontal line at the median value of the variable, placed within a box. The upper side of the box is the third quartile (the 75th percentile) and the lower side is the first quartile (the 25th percentile). Vertical line segments on both the upper and lower side of the box capture most of the rest of the distribution. The ends of these line segments are usually drawn at 1.5 times the inter-quartile range added to the third quartile and subtracted from the first quartile. These endpoints are called adjacent values in the box plot. The lines between the lower (upper) adjacent value and the 25th (75th) percentile range are called whiskers. Observations with values not contained within those values are usually added to the box plot as dots with their respective values. The box plot conveys many important features of distributions such as their skewness and shows some of the quantiles in an explicit way. A smarter-looking alternative is the violin plot shown in Figure 3.8b. In essence, the violin plot adds a twist to the box plot by overlaying a density plot on it. Violin plots show the density plot on both sides of the vertical line, but there is no difference between the two sides. In a sense, as with a box plot, we have two sides here purely to achieve a better look. Compared to the traditional box Adjacent line 4— Upper adjacent value Confidence interval Whiskers75th percentile Inter-quartile range MedianMedian Median Whiskers 4-— 25th percentile Adjacent line 4-— Lower adjacent values Confidence interval O outside values (a) Box plot (b) Violin plot Figure 3.8 The structure of the box plot and the violin plot 78 plot, the basic violin plot shows fewer statistics and does not show the extreme values. In exchange, it gives a better feel for the shape of the distribution. As there are many complementing features of box plots and violin plots, we advise you to consider both. Review Box 3.5 Summary statistics and their visualization • Measures of central value: Mean (average), median, other quantiles (percentiles), mode. • Measures of spread: Range, inter-quantile range, variance, standard deviation. • Measure of skewness: The mean-median difference. • The box plot is a visual representation of many quantiles and extreme values. • The violin plot mixes elements of a box plot and a density plot. in Football Distribution and summary statistics\
The idea of home team advantage is that teams that play on their home turf are more likely to play better and win compared to the same game played at the other team's stadium (the other team is also called the "away" team). In particular, this case study asks whether professional football (soccer) teams playing in their home stadium have an advantage and what is the extent of that advantage. These questions are interesting in order for fans to know what to expect from a game, but also for professional managers of football teams who want to maximize the number of wins and the support of fans. If home team advantage is important, managers need to know its magnitude to

benchmark the performance of their teams. Here we use data from the English Premier League, with the same data we started with in Chapter 2. Here we focus on games in the 2016/7 season. In each season, each pair of teams plays twice, once in the home stadium of one team, and once in the home stadium of the other team. This gives 380 games total (20 x 19: each of the 20 teams plays once at home against each of the other 19 teams). The observations in the data table we use here are the games; there are N = 380 observations. The most important variables are the names of the home team and the away team and the goals scored by each team. From these two quantitative variables we created a goal difference variable: home team goals — away team goals. Examining the distribution of this goal difference can directly answer our question of whether there is a home team advantage and how large it is. Let's look at the distribution of the home team — away team goal difference first. Figure 3.9 shows the histogram. While the goal difference is a quantitative variable, it doesn't have too many values so we show a histogram that shows the percentage of each value instead of bins. The mode is zero: 22.1 % of the games end with a zero goal difference (a draw). All other goal differences are of smaller percentage - the larger the difference, the smaller their frequency. This gives an approximately bell-shaped curve, except it is skewed with more observations (taller bars)

3.C1 Case Study 79

to the right of zero. That suggests home team advantage already. But let's look more closely into this histogram. The most striking feature of the histogram is that for each absolute goal difference, the positive value is more frequent than the negative value. The home team — away team goal difference is +1 in 20.8% of the games while It IS —1 in 13.2% of the games; it's +2 in 17.1% of the games and —2 in only 8.2% of the games, and so on. This clearly shows that home teams score more goals so there is a home team advantage. It also seems pretty large. But how large is it? To answer that we need to provide a number and put it into context.

Figure 3.9 The distribution of home team away team goal difference Source: football dataset. English Premier League, season 2016—2017, all games. N=380. To that end, we calculated the mean and the standard deviation of the goal difference as shown in Table 3.7. Moreover, we calculated the relative frequency of games in which the home team wins (positive goal difference), games in which the away team wins (negative goal difference), and games that end with a draw (zero goal difference: we know their proportion is 22%). Table 3.7 shows the results. Table 3.7 Statistic Value Mean 0.4 Standard deviation 1.9 Percent positive 49 380

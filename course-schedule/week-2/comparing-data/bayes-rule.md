# Bayes' Rule

"Inverse conditional probabilities are two conditional probabilities, in which the role of the conditioning event and the conditional event are switched. Suppose that we want to know if an athlete used an illegal substance (doping). For this case, we collect lab tests. Does the positive result of the test indicate that there is an illegal substance in the body of the athlete? In other words, we are interested in whether the athlete has doped given the positive test result. But tests are imperfect, so a test result will not reveal doping for sure. Instead, what we may hope for is a probability: the likelihood that someone doped, or not doped, given the result of the test. These are conditional probabilities: P(doped | positive) and P(not doped | positive). The imperfection of tests means that they may give positive results even if athletes don't dope: P(positive I not doped) > 0. Tests that are used in real life are usually validated so the level of their imperfection is known. Thus we typically know P(positive | not doped). What we are interested is the inverse probability: P(not doped | positive). The relation of inverse conditional probabilities tells us how the imperfect nature of a doping test determines how confident we can be in concluding that an athlete doped if the result of the test is positive. The two inverse conditional probabilities are related although their relations might seem complicated. We can derive one from the other using the formula that links conditional probabilities and joint probabilities as both are related to the same joint probability, the probability of both eventl and event2 occurring. The relation is called Bayes' rule after the Reverend Bayes who was the first to express this formula, in the seventeenth century P(eventl I event2) P(event2) P(eventl I event2)P(event2) + P(eventl I N) The most important message of this formula is that inverse conditional probabilities are not the same in general. The formula is also complicated. Instead of memorizing the formula we suggest using a different approach. This approach amounts to thinking in terms of frequencies and proportions in place of abstract probabilities. Consider our doping example: what's the likelihood that an athlete is a doper (or a non-doper) if they receive a positive test result? Start with assuming that a fifth of the athletes dope. Out of, say, 1000 athletes that means 200 doping and 800 not doping. Consider a test that is imperfect but not bad: it always shows a positive result when the athlete dopes, but it also shows positive results 10% of the times if an athlete does not dope. The former means that the test will be positive for all 200 dopers. The latter means that the test will also be positive for 10% of the non-dopers, which would be 80 out of the 800. In total we have 280 positive tests out of 1000. Of these 280 positives 200 are dopers and 80 non-dopers. We don't know which 200 are dopers and which 80 are non-dopers, but we can use these figures to calculate probabilities. The probability that an athlete is a doper if their test is positive is 200/280 = 71 % approximately. The probability that an athlete is not a doper if their test is positive is 80/280 = 29% approximately. This may look surprising: a relatively small imperfection (10% of positive results for non-dopers) results in a much larger drop in our confidence: the chance that a positive tester did not dope in fact is 29%. (Working through the formulae gives the same result.) The inverse conditional probability is larger because we started with the assumption that only 20% of athletes dope. This example highlights several important things. First, working through the frequencies is not super-easy, but it is doable. Second, however we carry out the calculation we need the probability that the test comes out positive for each of the groups, dopers and non-dopers (these are P(eventl I event2) and P(eventl | event2)). Third, we need the overall fraction of athletes that dope. That is P(event2) in the formulae above. This proportion is sometimes called the base rate. Without the base rate we can't compute the inverse probability. Unfortunately, we may not know the base rate. A good practice in such cases is to use several plausible values and give a range of inverse conditional probabilities. In our example, we assumed a base rate of 20%: 200 out of 1000 athletes use doping. If, instead we assumed a 5% base rate (50 out of 1000 doped) a test with a 10% positive rate for non-dopers (and 100% positive rate for dopers) would result in 50 dopers among the positively tested and 95 non-dopers (10% of 950). Thus the likelihood of doping conditional on a positive test is only 34% (= 50/(50 + 95). On the other hand, if we assumed a 50% base rate (500 out of 1000 doped) the same test would result in 500 dopers among the positively tested and 50 non-dopers. In this case the likelihood of doping conditional on a positive test is a high 91 % (= 500/(500 + 50). The base rate has a substantial effect on the result. With few dopers an imperfect test would give more misleading results than the same imperfect test with many dopers.

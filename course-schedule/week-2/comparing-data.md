---
description: Week 2, Lecture A2.2, 1500 words, 1 hour to complete
---

# Comparing Data



Review Box 4.6 Covariance and correlation The covariance measures the mean-dependence of two variables: Cov\[x, y] • The correlation coefficient is a standardized version of the covariance and ranges between —1 and 1: Corr\[x,y] • The covariance and the correlation are both zero if the variables are independent, positive if the variables are positively associated, and negative if they are negatively associated. From Latent Variables to Observed Variables Before closing the chapter, let's discuss two more topics briefly The first one is the concept of latent variables. Often, the y or x variables we have in question are abstract concepts: the quality of management of a firm, skills of an employee, risk tolerance of an investor, health of a person, wealth of a country Typically, such variables are not parts of an actual dataset, and they can't be because they are too abstract. Such variables are called latent variables. Data analysis can help answer questions involving latent variables only by substituting observed variables for them. Those observed variables are called proxy variables, where "proxy" means substitute (the word proxy is used as noun, adjective, and verb). The quality of management may be proxied by answers to survey questions on management practices, as in our case study; employee skills may be proxied by qualifications or measures of past performance; and so on. The most important thing to keep in mind here is that data analysis compares values of measured variables. Even if those variables are supposed to measure abstract concepts, it's never the abstract concepts themselves that we have in our data. Thus we can never examine things such as skills or attitudes or health; instead, we examine proxies such as measures of performance, answers to survey questions, or results of doctors' diagnoses. This is simply re-iterating the point we made earlier in Chapter 1, Section 1.3: the content of a variable is determined by how it is measured — not by what name somebody attached to it. A specific issue arises when our data contains not one but more variables that could serve as proxies to the latent variable we want to examine. The question here is how to combine multiple observed variables. Data analysts use one of three main approaches: Use one of the observed variables Take the average (or sum) of the observed variables Use principal component analysis (PCA) to combine the observed variables. Using one measured variable and excluding the rest has the advantage of easy interpretation. It has the disadvantage of discarding potentially useful information contained in the other measured variables. Taking the average of all measured variables makes use of all information in a simple way. When all of those variables are measured using the same scale, this approach yields a combined measure with a natural interpretation. When the variables are measured at different scales, we need to bring the observed variables to the same scale. Usually, we do that by standardizing them: subtracting the mean and dividing by the standard deviation (see Chapter 3, Section 3.6). This standardized measure is also called a z-score. By taking a simple average of all these variables we give them equal weight. This may be a disadvantage if some of the variables are better measures of the latent variable than others. The third approach remedies that problem. Principal component analysis (PCA) is a method to give higher weights to the observable variables that are better measures. PCA finds those weights by examining how strongly they would be related with the weighted average. The logic is an iterative process: create an average, examine how each variable is related to it by looking at their correlations, give 4.A4 Case Study 111 higher weights to those with stronger correlation, start over. The actual technique takes an ingenious approach to do the whole thing in one step. Of the three approaches, we recommend the second one: taking a simple average of the observed variables after making sure that they are measured at the same scale. This is the simplest way to combine all variables in a meaningful way. In principle, PCA produces a better combined measure, but it is more complicated to produce and harder to present to non-expert audiences. Moreover, it often gives similar results to a simple average. Thus we recommend that PCA is used as a robustness check, if at all. If the results of our analysis are very different with a simple average and with a PCA measure, some of our observed variables are very differently related to the average measure than others. It is good practice then to go back and understand the content of those variables and, perhaps, discard some of them from the analysis. Review Box 4.7 Latent and proxy variables • Latent variables are abstract concepts that are not actual variables in the data. • Proxy variables (proxies) are variables in the data that measure latent variables. • When more proxy variables are available for a single latent variable it is good practice to take their average, after making sure that they are measured on the same scale (for example, by standardizing them). CASE STUDY — Management Quality and Firm Size: Describing Patterns of Association Correlation and latent variable The covariance between firm size and the management score in the Mexican sample we use is 177. The standard deviation of firm size is 977; the standard deviation of management score is 0.6. The correlation coefficient is 0.30 (177/(977 \* 0.6) =0.30). This result shows a positive association: firms with more employees tend to have a higher management score. The magnitude of the correlation is moderate, presumably because many other things matter for the quality of management besides the size of a firm. Table 4.1 shows the correlation coefficient in seven broad categories of industrial classification (plus one "other" category with the industries with very few firms, combined). Table 4.1 Management score and employment: correlation and average management score by industry Industry Management—employment correlation Observations Auto Chemicals Electronics, equipment, machinery 0.50 0.05 0.28 26 69 36

Management—employment Industry correlation Observations

Food, drinks, tobacco 0.05 34 Materials, metals 0.32 50 Textile, apparel, leather 0.36 38 Wood, furniture, paper 0.28 37 Other 0.63 10 All 0.30 300

Source: wms-management-survey dataset. Mexican firms with 100—5000 employees. N=300. The table reveals that the management quality-firm size correlation varies considerably across industries. The correlation is strongest in the auto and "other" industries. At the same time, we see hardly any correlation among firms in the chemicals and food industries. Before concluding our case study, note that it illustrates the measurement issues related to latent variables, too. From a conceptual point of view, the y variable in our case study is management quality, a latent variable. We have 18 measures for this latent variable in the data; those are the 1 8 score variables on the quality of various aspects of management. Each of these 18 variables is measured by the survey (as we discussed in Chapter 1, Section 1 .C 1), and each is measured on the same I-to-5 scale. For the measure of the overall quality of management, we used two of the three strategies we recommended in Section 4.7. To illustrate conditional probabilities, visualized by the stacked bar charts in Figures 4.3a and 4.3b, we used 2 of the 18 score variables. Each one is an imperfect measure of the overall quality of management, but each has a clear interpretation: the rating of the particular aspect of management quality by the interviewer For most of the case study, we used the average score: the simple average of the 18 scores. We could use this simple average because each of the 18 variables aimed to measure an aspect of the same thing, management quality, and each was measured on the same scale (1 to 5). As a data exercise you are invited to try the third option we recommended in Section 4.7, and create a principal component from the 18 scores instead of their simple average. When analyzing the relationship between firm size and management quality, using this principal component measure turns out to give very similar results to what we have uncovered using the average score measure. This concludes our case study. What did we learn from it about the association between firm size and management quality? We found that, among Mexican manufacturing firms, larger firms tend to be better managed. Large firms (with 1000-5000 employees) have an average score of 3.19, compared to 2.94 for medium-sized firms (with 200—999 employees), and 2.68 for small ones (with 100-199 employees). We also found that the correlation, while positive, is not very strong, perhaps because other things matter for the quality of management besides firm size. When disaggregating the results into smaller industry groups, we found that the strength of the management—size correlation differs in some industries from the rest, but we haven't seen any clear pattern that would tell us why. Finally,

```
4.8 Sources of Variation in x	113
```

we have seen that management quality is not only better, on average, among larger firms, but it is also somewhat more spread among larger firms. These results inform the business or policy questions we may be interested in. When considering the management practices of a specific firm, we should have firms of similar size as a benchmark. And, better management of a larger firm may be a potential benefit of increased firm size — e.g., through a merger between companies. As for the methods discussed in this chapter, this case study illustrated what we can do to uncover patterns of associations and conditional distributions when both y and x are quantitative variables. We have seen that creating bins from x can lead to informative visualizations, such as a bin scatter or box plots of y by bins of x. Three bins (small, medium, large) appeared a good choice in our case. For example, the bin scatter with ten bins did not give much more information than the bin scatter with three bins. We have also seen that the correlation coefficient is a useful statistic to summarize mean-dependence between y and x, and it allows us to dig a little deeper by showing whether and how the correlation differs across groups by a third variable (here industry). Finally, we have seen that, with rich enough data, we can use an average score variable calculated from many (here 18) variables to measure a latent variable, management quality in our case study. Sources of Variation in x Our final section in this chapter is a note on variation in x, the variable (or variables) we condition on to make comparisons in y. The first thing to note is that we need variation in x, and the more variation we have the better in general. In data with no variation in x, all observations have the same values and it's impossible to make comparisons. This may sound trivial, but it's essential to keep in mind. Similarly, the more variation in x, the better the chances for comparison. For example, when data analysts want to uncover the effect of price changes on sales, they need many observations with different price values. If prices don't change at all, there is no way to learn how they may affect sales. If prices change very rarely or the changes are negligible in magnitude, there isn't much room for comparison and thus there isn't much to learn. The second question is where that variation in x comes from. As we shall see in subsequent chapters (e.g., Chapters 19 through 24), data analysts need to understand the sources of variation in x. This is a somewhat fancy way of saying that data analysts should have a good understanding of why values of x may differ across observations. From this perspective, there are two main types of data: experimental data and observational data. In experimental data, the value of x differs across observations because somebody made them different. In a medical experiment assessing the effects of a drug, some patients receive the drug while others receive a placebo, and who receives what is determined by a rule designed by the experimenter, such as a coin flip or a computer generated sequence of numbers. Here x is the binary variable indicating whether the person received the drug, instead of the placebo. Such variation is called controlled variation. Uncovering the effect of an experiment amounts to comparing y (such as whether a subject recovers from the illness or not) across the various values of x (whether a subject received the drug or not). In contrast, in observational data, no variable is fully controlled by an experimenter or any other person. Most data used in business, economics, and policy analysis are observational. Typical variables in such data are the results of the decisions of many people with diverging goals and circumstances, such as customers, managers of firms, administrators in a government, or members of the board of the monetary authority. Thus, typically, variation in these variables has multiple sources. Whether the variation in conditioning variables is controlled (experimental) or not (observational) is extremely important for causal analysis. Learning the effects of a variable x is a lot easier when we have data from an experiment, in which variation in x is controlled. With observational variation, of the many other things that affect an intervention variable, some may affect the outcome variable in a direct way, too. Disentangling those effects requires data analysts to further condition on many variables at the same time, using methods that we'll cover later in this textbook. Even with the best methods, conditioning on variables is possible only if those variables are measured in the data, which typically is not the case. We'll return to these questions in Chapter 10 and, in more detail, in Chapters 19 through 24. For example, the price of a product (x) sold by a retailer may vary across time. In a sense that variation has one source, the decisions of people in charge at the retail company. But that decision, in turn, is likely affected by many things, including costs, predicted customer demand, and the pricing decisions of competitors, all of which may change through time and thus lead to variation in prices. Here a data analyst may want to uncover what would happen if the retailer increased its price (x) on sales (y), using observational data. That requires conditioning on price: looking at differences in sales across observations with different prices. But the results of this comparison won't tell us what would happen if the retailer increased the price. That's because the question is about changing x as an autonomous decision, whereas, in the data, x tends to change together with some other things. The data analyst then may go on to try to further condition on those other things that are sources of variation, such as the price charged by the competitors, or seasonal variation in demand. If lucky, the data analyst may be able to measure all those variables. But that's a tall order in most cases. The power of experimental data is that there is no need to measure anything else. The other frequent goal of data analysis, making predictions about y, poses somewhat different requirements for variation in x. Understanding the sources of variation in x or, more realistically, the many variables, is still useful, although not in the way it is in causal analysis. Here the main question is stability: whether the patterns of association between y and all those x variables are the same in our data as in the situation for which we make the prediction. Controlled variation in x helps only in the rare case when x would also be controlled in the situation we care about. But uncovering cause and effect relationships can be helpful in prediction in general. We shall discuss these issues in more detail in Part Ill, from Chapter 13 through Chapter 18. This chapter introduced some fundamental concepts and methods of conditioning y on x, the statistical concept of comparing values of y by values of x (or more x variables). We'll return to conditioning yon x in Chapter 7 where we introduce regression analysis. Before doing so, we discuss some general principles and methods in the next chapter that help draw conclusions from our data about the situation we are really interested in. Main Takeaways Data analysis answers most questions by comparing values of y by values of x. Be explicit about what y and x are in your data and how they are related to the question of your analysis. E\[ylx] is mean y conditional on x. Data Exercises 115 Often many x variables are used for prediction and we may further condition on many other variables for causal analysis.

PRACTICE QUESTIONS l. Give an example with two independent events. Can independent events happen at the same time? 2. Give an example of two mutually exclusive events. Can mutually exclusive events happen at the same time? 3. What's the conditional probability of an event? Give an example. 4. What's the conditional mean of a variable? Give an example. 5. How is the correlation coefficient related to the covariance? What is the sign of each when two variables are negatively associated, positively associated, or independent? 6. Describe in words what it means that hotel prices and distance to the city center are negatively correlated. 7. When we want to compare the mean of one variable for values of another variable, we need variation in the conditioning variable. Explain this. 8. What's the difference between the sources of variation in x in experimental data and observational data? 9. What's the joint distribution of two variables, and how can we visualize it? 10. What's a scatterplot? What does it look like for two quantitative variables, each of which can be positive only, if the two variables are positively correlated? 11. What's a bin scatter, and what is it used for? 12. What's a latent variable, and how can we use latent variables in data analysis? Give an example. 13. List two ways to combine multiple measures of the same latent variable in your data for further analysis, and list an advantage and a disadvantage of each way. 14. You want to know if working on case studies in groups or working on them independently is a better way to learn coding in R. What would be your y and x variables here and how would you measure them? 15. Can you tell from the shape of a bin scatter if y and x are positively correlated? Can you tell from it how strong their correlation is? DATA EXERCISES Easier and/or shorter exercises are denoted by \[ _l; harder and/or longer exercises are denoted by \[_

1. Are central hotels better? To answer this, using the hotels-vienna dataset (as discussed in Chapter 3, Section 3.A1), create two categories by the distance from center: close and far (by picking a cutoff of your choice). Show summary statistics, compare stars and ratings and prices for close and far hotels. Create stacked bar charts, box plots, and violin plots. Summarize your findings.
2. Using the wms-management-survey dataset, pick a country different from Mexico, reproduce all figures and tables of our case study, and compare your results to what we found for Mexico.
3. Use the wms-management-survey dataset from a country of your choice, and create a management score from a meaningful subset of the 18 items (e.g. managing talent). Carry out

an analysis to uncover the patterns of association with employment. Summarize what you find, and comment on which visualization you find the most useful. \[ \* ] 4. Use the wms-management-survey dataset from a country of your choice, and produce a principal component using all 18 items to form an alternative management score variable. Use this principal component and the simple average management score to produce bin scatters, scatterplots, and calculate conditional statistics to uncover the patterns of their association with employment. Compare your results and comment on which y measure you would use in presenting them. \[ \* ] 5. Use the football dataset and pick a season. Create three groups of teams, based on their performance in the previous season (new teams come from the lower division, and you may put them in the lowest bin). Examine the extent of home team advantage (as in Chapter 3, Section 3.C 1) by comparing it across these three groups of teams. Produce bin scatters and scatterplots, and calculate conditional statistics. Discuss what you find, and comment on which visualization you find the most useful. \[ REFERENCES AND FURTHER READING Regarding the World Management Survey, you will find plenty of reading at the survey website at https://worldmanagementsurvey.org/academic—research/manufacturing—2/ — with links to papers. For a business perspective, you could have a look at the Harvard Business Review article by Bloom et al. (2017). For a more detailed review of the project, consider reading Bloom et al. (2014).

UNDER THE HOOD: INVERSE CONDITIONAL PROBABILITIES, BAYES' RULE As we introduced in Section 4.3, inverse conditional probabilities are two conditional probabilities, in which the role of the conditioning event and the conditional event are switched: P(eventl I event2) and P(event2 1 eventl). In this section we discuss their relationship to each other. Suppose that we want to know if an athlete used an illegal substance (doping). For this case we collect lab tests. Does the positive result of the test indicate that there is illegal substance in the body of the athlete? In other words, we are interested in whether the athlete has doped given the positive test result. But tests are imperfect so a test result will not reveal doping for sure. Instead, what we may hope for is a probability: the likelihood that someone doped, or not doped, given the result of the test. These are conditional probabilities: P(dopedl positive) and P(not doped I positive). (Knowing one of these two gives the other one as the two sum up to one.) Imperfection of tests mean that they may give positive results even if athletes don't dope: P(positive I not doped) > 0. Tests that are used in real life are usually validated so the level of their imperfection is known. Thus we typically know P(positivel not doped). What we are interested is the inverse probability: P(notdopedl positive). The relation of inverse conditional probabilities tells us how the imperfect nature of a doping test determines how confident we can be concluding that an athlete doped if the result of the test is positive. The two inverse conditional probabilities are related although their relation might seem complicated. We can derive one from the other using the formula that links conditional probabilities and

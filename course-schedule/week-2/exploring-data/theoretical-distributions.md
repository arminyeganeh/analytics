# Theoretical Distributions

"Theoretical distributions are distributions of variables with idealized properties ... But why should we care about theoretical distributions? The main reason is that they can be of great help when we want to understand important characteristics of variables in our data. Theoretical distributions are usually simple to describe and have a few well-established properties. If a variable in our data is well approximated by a theoretical distribution, we can simply attribute those properties to the variable without having to check those properties over and over. It turns out that there are surprisingly many real-world variables whose distributions are quite well approximated by one of the theoretical distributions.&#x20;

The **normal distribution** is the best-known and most widely used theoretical distribution of quantitative variables. It is a purely theoretical construct in the sense that it was derived mathematically from another distribution, **the binomial**. Variables with a normal distribution can in principle take on any value from negative infinity to positive infinity. The histogram of the normal distribution is **bell-shaped**. For that reason, the popular name for the normal distribution is **the bell curve**. It is also called the Gaussian distribution after the German mathematician who played a role in popularizing it (it was the French mathematician Laplace who first derived it). The normal distribution is characterized by two parameters, usually denoted as and o. They refer to the mean (g) and the standard deviation (o). The variance is the square of the standard deviation, 02 . A special case of the normal distribution is the standard normal distribution. It is a normal distribution with parameters 0 and 1: its mean is zero and its standard deviation is one (and thus its variance is also one). If a variable x is normally distributed with mean and standard deviation c, its transformed version is distributed standard normal if we take out the mean and divide this difference by the standard deviation:\
It turns out that when we transform a normally distributed variable by adding or multiplying by a number, the result is another normally distributed variable, with appropriately transformed mean and standard deviation. It also turns out that when we add two normally distributed variables, the resulting new variable is also normally distributed, and its mean is the sum of the means of the two original variables. (The standard deviation is a function of the original standard deviations and the correlation of the two variables.) Some variables in real life are well approximated by the normal distribution. The height of people in a population is usually approximately normal, and so is their IQ, a measure of intelligence (although that is in part because the tests behind the IQ measure are constructed that way). Variables in real life are well approximated by the normal distribution if they are a result of adding up many small things. We discuss this in detail in Under the Hood section 3.U1. The normal is a bad approximation to real-life variables with extreme values. Extreme values are very unlikely in the normal distribution. For example, the normal distribution formula (see Under the Hood section 3.U1) suggests that only 0.3% of the values of a normally distributed variable should be more than three standard deviations above the mean; only 0.000 000 2% should be higher than six standard deviations above the mean.

3.D1 Case Study Besides the absence of extreme values, symmetry is another feature of the normal distribution that makes it a bad approximation to many economic variables. Earnings, income, wealth, and firm productivity are usually asymmetrically distributed with long right tails. One theoretical distribution that may be a better approximation to such variables is the lognormal distribution. The lognormal distribution is very asymmetric, with a long right tail, potentially including many extreme values at the positive end (but not at the other end). The lognormal distribution is derived from the normal distribution. If we take a variable that is distributed normally (x) and raise e to its power (ex), the resulting variable is distributed lognormally. The old variable is the natural logarithm of the new variable, hence the name of the new distribution (the log of which is normal). Because we raised e to the power of the original variable, the values of the resulting lognormal variable are always positive. They range between zero and positive infinity (never reaching either). By convention, the parameters of the lognormal are the mean and standard deviation o of the original, normally distributed variable, which is the logarithm of the new variable. Thus the mean and the standard deviation of the lognormal are complicated functions of these parameters. They are: e and\
There are real-life variables that are approximately lognormally distributed. These include distributions of price, income, and firm size. Variables are well approximated by the lognormal if they are the result of many things multiplied together (the natural log of them is thus a sum). Another way to think about lognormal variables is that their percentage differences are normally distributed. Thus, they do not have many extreme values in terms of percentage differences. (Note that normally distributed percentage differences translate into quite extreme differences in terms of absolute values.)&#x20;

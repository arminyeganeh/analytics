# Variability

"A measure of center alone is not adequate for numerically describing data for a quantitative variable. It describes a typical value, but not the spread of the data about that typical value." (Agresti, 2018)

"The range is the difference between the largest and smallest observations." (Agresti, 2018)

"Each observation has a deviation. The deviation is positive when the observation falls above the mean. The deviation is negative when the observation falls below the mean. The interpretation of y as the center of gravity of the data implies that the sum of the positive deviations equals the negative of the sum of negative deviations. Thus, the sum of all the deviations about the mean, E(Yi — y), equals 0. Because of this, measures of variability use either the absolute values or the squares of the deviations. The most popular measure uses the squares ... The variance is approximately an average of the squared deviations."

"The reason for using (n 1), rather than n, in the denominator of s (and s2 ) is a technical one regarding inference about population parameters. When we have data for an entire population, we replace (n 1) by the actual population size; the population variance is then precisely the mean of the squared deviations." (Agresti, 2018)

"The mean of a quantitative variable is the value that we can expect for a randomly chosen observation. The mean of a 0/1 binary variable is the proportion of observations with a value of 1. Similarly, most readers know the most important **measures of spread**, such as the range (the difference between the largest and smallest value), inter-quantile ranges (e.g., the 90—10 percentile range, or the inter-quartile range), the standard deviation, and the variance. The standard deviation captures the typical difference between a randomly chosen observation and the mean. The variance is the square of the standard deviation. The variance is a less intuitive measure, but it is easier to work with because it is a mean value itself. Note that alternative formulae for the variance and the standard deviation divide by (n - 1) not (n). Most data are large enough that this makes no practical difference. It turns out that dividing by (n - 1) is the correct formula if we use the statistic in the data to infer the standard deviation in the population that our data represents." (Bekes, 2021)
